"""
Processing CSV format definitions for PyAMA trace data.

This module defines the data structures and utilities for handling CSV files
generated by the processing module. The format includes FOV-level trace data
with cell tracking information.

Format: fov, cell_id, frame, intensity_total, area, x_centroid, y_centroid, [good]
"""

import pandas as pd
from pathlib import Path
from dataclasses import dataclass
from typing import Optional, List
import logging

logger = logging.getLogger(__name__)


@dataclass
class ProcessingTraceRecord:
    """
    Represents a single trace record from processing CSV output.
    
    Attributes:
        fov: Field of view index
        cell_id: Cell identifier within the FOV
        frame: Frame number in the time series
        intensity_total: Total fluorescence intensity
        area: Cell area in pixels
        x_centroid: X coordinate of cell centroid
        y_centroid: Y coordinate of cell centroid
        good: Quality flag (optional, from visualization filtering)
    """
    fov: int
    cell_id: int
    frame: int
    intensity_total: float
    area: float
    x_centroid: float
    y_centroid: float
    good: bool = True


class ProcessingCSVLoader:
    """
    Loader for processing CSV files containing trace data.
    
    Handles loading and validation of CSV files generated by the processing module.
    Expected format: fov, cell_id, frame, intensity_total, area, x_centroid, y_centroid, [good]
    """
    
    REQUIRED_COLUMNS = [
        'fov', 'cell_id', 'frame', 'intensity_total', 
        'area', 'x_centroid', 'y_centroid'
    ]
    OPTIONAL_COLUMNS = ['good']
    
    def load_fov_traces(self, csv_path: Path) -> pd.DataFrame:
        """
        Load trace data from a processing CSV file.
        
        Args:
            csv_path: Path to the processing CSV file
            
        Returns:
            DataFrame with trace data
            
        Raises:
            FileNotFoundError: If the CSV file doesn't exist
            ValueError: If the CSV format is invalid
        """
        if not csv_path.exists():
            raise FileNotFoundError(f"CSV file not found: {csv_path}")
            
        try:
            df = pd.read_csv(csv_path)
            
            if not self.validate_format(df):
                raise ValueError(f"Invalid CSV format in {csv_path}")
                
            # Ensure 'good' column exists with default True values
            if 'good' not in df.columns:
                df['good'] = True
                
            logger.info(f"Loaded {len(df)} trace records from {csv_path}")
            return df
            
        except Exception as e:
            logger.error(f"Failed to load CSV file {csv_path}: {e}")
            raise
    
    def validate_format(self, df: pd.DataFrame) -> bool:
        """
        Validate that the DataFrame has the expected processing CSV format.
        
        Args:
            df: DataFrame to validate
            
        Returns:
            True if format is valid, False otherwise
        """
        # Check required columns are present
        missing_cols = [col for col in self.REQUIRED_COLUMNS if col not in df.columns]
        if missing_cols:
            logger.error(f"Missing required columns: {missing_cols}")
            return False
            
        # Check data types
        try:
            # Ensure numeric columns are numeric
            numeric_cols = ['fov', 'cell_id', 'frame', 'intensity_total', 'area', 'x_centroid', 'y_centroid']
            for col in numeric_cols:
                if col in df.columns:
                    pd.to_numeric(df[col], errors='raise')
                    
            # Check 'good' column if present
            if 'good' in df.columns:
                if not df['good'].dtype == bool and not df['good'].isin([0, 1, True, False]).all():
                    logger.error("'good' column must contain boolean values")
                    return False
                    
        except (ValueError, TypeError) as e:
            logger.error(f"Invalid data types in CSV: {e}")
            return False
            
        return True
    
    def get_cell_count(self, csv_path: Path) -> int:
        """
        Get the number of unique cells in a processing CSV file.
        
        Args:
            csv_path: Path to the processing CSV file
            
        Returns:
            Number of unique cells
        """
        try:
            df = self.load_fov_traces(csv_path)
            return df['cell_id'].nunique()
        except Exception as e:
            logger.error(f"Failed to get cell count from {csv_path}: {e}")
            return 0
    
    def get_fov_metadata(self, csv_path: Path) -> dict:
        """
        Extract metadata from a processing CSV file.
        
        Args:
            csv_path: Path to the processing CSV file
            
        Returns:
            Dictionary with metadata (fov_index, cell_count, has_quality_data, frame_count)
        """
        try:
            df = self.load_fov_traces(csv_path)
            
            metadata = {
                'fov_index': df['fov'].iloc[0] if len(df) > 0 else 0,
                'cell_count': df['cell_id'].nunique(),
                'has_quality_data': 'good' in df.columns,
                'frame_count': df['frame'].nunique(),
                'file_path': csv_path
            }
            
            return metadata
            
        except Exception as e:
            logger.error(f"Failed to extract metadata from {csv_path}: {e}")
            return {
                'fov_index': 0,
                'cell_count': 0,
                'has_quality_data': False,
                'frame_count': 0,
                'file_path': csv_path
            }
    
    def filter_good_traces(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Filter DataFrame to include only traces marked as 'good'.
        
        Args:
            df: DataFrame with trace data
            
        Returns:
            Filtered DataFrame containing only good traces
        """
        if 'good' not in df.columns:
            logger.warning("No 'good' column found, returning all traces")
            return df
            
        good_traces = df[df['good'] == True].copy()
        logger.info(f"Filtered {len(df)} traces to {len(good_traces)} good traces")
        return good_traces