This is a test file for the tokenization task.

The tokenization process will:
1. Read this text file
2. Sleep for 1 minute to simulate processing
3. Use tiktoken to tokenize the text with the cl100k_base encoding (GPT-4)
4. Write the tokenized output to a JSON file

This demonstrates how the PyAMA FastAPI backend can handle long-running tasks
with file I/O operations and progress tracking. The task can be monitored by
polling the /tasks/{task_id} endpoint to see real-time progress updates.
